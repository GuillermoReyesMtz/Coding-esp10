{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task2_BERT_CODIESP_0-1.ipynb","provenance":[{"file_id":"1QfPdlL3bOy-ES23SCCiRjTsOrFBdewkb","timestamp":1588870811355},{"file_id":"1wqPP9eWipx6Gg2aJKU3nwp4gEhgAKUFe","timestamp":1588435102740}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"EgowscHBpR34","colab_type":"code","outputId":"a9b384a6-a71e-46df-8e0a-6247618290f9","executionInfo":{"status":"ok","timestamp":1588925353073,"user_tz":-120,"elapsed":112471,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install tensorflow-gpu==1.15\n","# @title Preparation\n","!pip install -q keras-bert keras-rectified-adam\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n","\u001b[K     |████████████████████████████████| 411.5MB 40kB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.10.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 39.2MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.28.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.2.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15) (46.1.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=66a7a0ad415d47d60af5371cc539fd37b1540dd5565090b1d3c5705c192ea14d\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.2.0rc4 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0rc4 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0rc4 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 2.2.1\n","    Uninstalling tensorboard-2.2.1:\n","      Successfully uninstalled tensorboard-2.2.1\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RTP0Zqanppi6","colab_type":"code","outputId":"8d9719d8-452e-43b4-962b-63aefe272c2d","executionInfo":{"status":"ok","timestamp":1588925354579,"user_tz":-120,"elapsed":4344,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","import keras\n","from keras_radam import RAdam\n","from keras_bert import get_custom_objects\n","import numpy as np\n","from tqdm import tqdm\n","from keras_bert import Tokenizer\n","import pandas as pd\n","import tensorflow.keras.backend as K\n","import sys\n","from sklearn.metrics import classification_report\n","from google.colab import drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"M30Oo53cqUX2","colab_type":"code","colab":{}},"source":["# @title Constants\n","\n","np.random.seed(42)\n","SEQ_LEN = 128\n","BATCH_SIZE = 8\n","EPOCHS = 5\n","LR = 1e-5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CK2pzzyrnDz","colab_type":"code","colab":{}},"source":["# @title Environment\n","import os\n","pretrained_path = '/content/drive/My Drive/codiesp/'\n","config_path = os.path.join(pretrained_path, 'config.json')\n","checkpoint_path = os.path.join(pretrained_path, 'model.ckpt-2000000')\n","vocab_path = os.path.join(pretrained_path, 'vocab.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZF3iLwpqZGn","colab_type":"code","outputId":"c48219b6-75c9-4286-f717-470bdd2a7030","executionInfo":{"status":"ok","timestamp":1588925358099,"user_tz":-120,"elapsed":2908,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["# @title Load Basic Model\n","import sys\n","\n","!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n","if not 'bert_repo' in sys.path:\n","  sys.path += ['bert_repo']\n","\n","# import python modules defined by BERT\n","from run_classifier import *\n","import modeling\n","import optimization\n","import tokenization\n","\n","import codecs\n","from keras_bert import load_trained_model_from_checkpoint\n","\n","token_dict = {}\n","with codecs.open(vocab_path, 'r', 'utf8') as reader:\n","    for line in reader:\n","        token = line.strip()\n","        token_dict[token] = len(token_dict)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Cloning into 'bert_repo'...\n","remote: Enumerating objects: 340, done.\u001b[K\n","remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n","Receiving objects: 100% (340/340), 300.28 KiB | 8.12 MiB/s, done.\n","Resolving deltas: 100% (185/185), done.\n","WARNING:tensorflow:From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0BTrr5musRIE","colab_type":"code","outputId":"b978c857-472a-4dcd-d4d0-6950b113b56c","executionInfo":{"status":"ok","timestamp":1588925389205,"user_tz":-120,"elapsed":31096,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":379}},"source":["# @title Load Data\n","!pip install category_encoders==1.3.0\n","import joblib\n","import pandas as pd\n","from keras import Sequential\n","from keras_preprocessing.sequence import pad_sequences\n","from keras_preprocessing.text import Tokenizer\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import numpy as np\n","import random\n","from keras.layers import Input\n","import keras\n","from keras.layers import Conv1D , Embedding\n","from keras.layers import Dropout\n","from keras.layers import MaxPool1D\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.layers import GlobalMaxPool1D\n","from keras.layers import Bidirectional\n","import category_encoders as ce\n","\n","from keras.callbacks import ModelCheckpoint\n","from keras_self_attention import SeqSelfAttention\n","\n","def remove_symbol(s):\n","    s = s.replace(\",\", \"\")\n","    s = s.replace(\".\", \"\")\n","    s = s.replace(\";\", \"\")\n","    s = s.replace(\":\", \"\")\n","    s = s.replace(\"_\", \"\")\n","    s = s.replace(\"+\", \"\")\n","    s = s.replace(\"ª\", \"\")\n","    s = s.replace(\"-\", \"\")\n","    s = s.replace(\"<\", \"\")\n","    s = s.replace(\">\", \"\")\n","    s = s.replace(\"!\", \"\")\n","    s = s.replace(\"?\", \"\")\n","    s = s.replace(\"(\", \"\")\n","    s = s.replace(\")\", \"\")\n","    s = s.replace(\"[\", \"\")\n","    s = s.replace(\"]\", \"\")\n","    s = s.replace(\"'\", \"\")\n","    s = s.replace(\"0\", \"\")\n","    s = s.replace(\"1\", \"\")\n","    s = s.replace(\"2\", \"\")\n","    s = s.replace(\"3\", \"\")\n","    s = s.replace(\"4\", \"\")\n","    s = s.replace(\"5\", \"\")\n","    s = s.replace(\"6\", \"\")\n","    s = s.replace(\"7\", \"\")\n","    s = s.replace(\"8\", \"\")\n","    s = s.replace(\"9\", \"\")\n","    s = s.replace(\"%\", \"\")\n","    s = s.strip()\n","    s = s.lower()\n","    return s\n","\n","# Rimozione delle stopword\n","def clar_text(text):\n","\n","    t = remove_symbol(str(text).strip().lower())\n","    tokens = list(str(text).lower().split(\" \"))\n","    for z in range(0, len(stop_word)):\n","        if stop_word[z] in tokens:\n","            while stop_word[z] in tokens:\n","                tokens.remove(str(stop_word[z]))\n","\n","    tt = \"\"\n","    for it in tokens:\n","      tt = tt +\" \"+it\n","    return tt\n","\n","def _pad(input_ids, max_seq_len):\n","    x = []\n","    input_ids = input_ids[:min(len(input_ids), max_seq_len - 2)]\n","    input_ids = input_ids + [0] * (max_seq_len - len(input_ids))\n","    return np.array(input_ids)\n","\n","#LOADING DATASET\n","df = pd.read_csv('/content/drive/My Drive/codiesp/Train_with_emptyclass_Task2.csv')\n","df = df[['Code', 'Desc']]\n","# df = df[pd.notnull(df['desc'])]\n","#print(df.head(10))\n","#print(df.shape)\n","\n","df.index = range(df.shape[0])\n","print(\"Parole: \" + str(df['Desc'].apply(lambda x: len(x.split(' '))).sum()))  # ci sono circa 211456 parole\n","\n","# rimozione SOLO dei simboli (nessuno stemming e nessuna rimozione delle stopword)\n","df['Desc'] = df['Desc'].apply(remove_symbol)\n","#print(df.head(10))\n","\n","# Acquisizione delle stop word\n","file_stopw = open(\"/content/drive/My Drive/codiesp/stop_word.pck\", \"rb\")\n","stop_word = pickle.load(file_stopw)\n","df['Desc'] = df['Desc'].apply(clar_text)\n","\n","#suddivisione train_test\n","train = df\n","\n","df1 = pd.read_csv('/content/drive/My Drive/codiesp/TestSet.csv')\n","df1 = df1[['id', 'Desc']]\n","# rimozione SOLO dei simboli (nessuno stemming e nessuna rimozione delle stopword)\n","df1['Desc'] = df1['Desc'].apply(remove_symbol)\n","df1['Desc'] = df1['Desc'].apply(clar_text)\n","test = df1\n","\n","#prepare class encoder\n","le = ce.OneHotEncoder(return_df=False, impute_missing=False, handle_unknown=\"ignore\")\n","labels = le.fit(list(df['Code']))\n","#mapa = [0,1]\n","mapa = le.category_mapping[0]['mapping']\n","labels_map = []\n","i = 0\n","for a,b in mapa:\n","    labels_map.append(a)\n","print(labels_map)\n","\n","#Tokenization\n","#Inizialize the tokenizer\n","tokenizer = tokenization.FullTokenizer(vocab_path, do_lower_case=True)\n","indices_train = []\n","indices_test = []\n","\n","for text in train['Desc']:\n","  tk = tokenizer.tokenize(text)\n","  tokens = [\"[CLS]\"] + tk + [\"[SEP]\"]\n","  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","  token_ids = _pad(token_ids,SEQ_LEN)\n","  indices_train.append(token_ids)\n","\n","for text in test['Desc']:\n","  tk = tokenizer.tokenize(text)\n","  tokens = [\"[CLS]\"] + tk + [\"[SEP]\"]\n","  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","  token_ids = _pad(token_ids,SEQ_LEN)\n","  indices_test.append(token_ids)\n","\n","indices_train = [indices_train, np.zeros_like(indices_train)]\n","indices_test= [indices_test, np.zeros_like(indices_test)]\n","\n","train_labels = train['Code']\n","train_labes_indexes = []\n","for label in train_labels:\n","  train_labes_indexes.append(labels_map.index(label))\n","\n","test_ids = test['id']\n","#test_labes_indexes = []\n","#for label in test_labels:\n","#  test_labes_indexes.append(labels_map.index(label))\n","\n","#print(test_labels)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting category_encoders==1.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/d3/82a4b85a87ece114f6d0139d643580c726efa45fa4db3b81aed38c0156c5/category_encoders-1.3.0-py2.py3-none-any.whl (61kB)\n","\r\u001b[K     |█████▍                          | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n","\u001b[?25hRequirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==1.3.0) (0.5.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==1.3.0) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==1.3.0) (0.22.2.post1)\n","Requirement already satisfied: pandas>=0.20.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==1.3.0) (1.0.3)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==1.3.0) (1.18.3)\n","Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==1.3.0) (0.10.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders==1.3.0) (1.12.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.1->category_encoders==1.3.0) (0.14.1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->category_encoders==1.3.0) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->category_encoders==1.3.0) (2018.9)\n","Installing collected packages: category-encoders\n","Successfully installed category-encoders-1.3.0\n","Parole: 151918\n","['bv44zzz', 'bw40zzz', 'bn20', 'bw03zzz', '3E02329', 'emp', '0tjb8zz', '0ttb', '0ul7', 'bw4gzzz', '0vbg', '0vtg', '0vtb', 'bw20', 'bw21', '0fy0', '0t9b', 'b030', '0DJDXZZ', 'bv49zzz', 'bt40zzz', '0vb08zz', '0yu5', '0dj68zz', '0djd8zz', '0tt00zz', '0t91', '0db6', 'bt43zzz', '0ujmxzz', '10d00z1', '0tt6', 'bt41zzz', 'bt21', '0tt0', '0tb6', 'bt4jzzz', 'bf35', '0vt9', '0TB13ZX', 'bt22', 'bw25', 'bw30', '0tt60zz', 'bt23', '0vb0', '0dbe', 'bf25', '0j98', '0dbg', '0tf3', '0tbb', '0tbb8zx', 'bt04zzz', '0t78', '10e0xzz', 'bw0lzzz', '0t7d', '0t5d', '0tt04zz', '0tb0', '4a02x4z', 'bt13', 'bw00zzz', '0vb90zz', 'bv35zzz', 'bv37zzz', 'bv37', '0vtj', '10d0', '0wjg', '0vc0', 'bt15', 'b33r', 'bw2g', 'b836', '0djdxzz', '0vb00zz', '0k9q', '0vt0', 'BV44ZZZ', 'bw24', '0vbs', '3e0t3cz', '0vt3', '0tt1', 'BT22ZZZ', 'BF27ZZZ', 'BT42ZZZ', '0vtf0zz', '0yq5', 'BT40ZZZ', 'bt20', '0vt90zz', 'bw3g', '07tp', '10a0', 'bt10', 'bf11', 'BT4JZZZ', '3e03', '0ty00z0', 'bt29', 'bt49zzz', '5a1d', '0vtc', '07dq', 'cp1z', 'bw2f', '3e1k', '0tbb8zz', 'n28.89', '07bd', 'bt42zzz', 'bt12', '0tb1', '0tcb', '0tcb0zz', '0tjb', 'BT43ZZZ', '0k9n', '0st40zz', 'br29', '0k9p', '0vttxzz', 'bv30', 'bv4bzzz', '3e0k', '0tb78zz', '0tb10zz', '07tc', 'bt14', '0vrb0jz', '0dj6', '0d16', '0t90', 'BD49ZZZ', 'BD42ZZZ', 'BV49ZZZ', '0t73', 'bv34', '3e0t', '0f19', '09fg', '0ft44zz', '0t18', '0tbd', '0wjg4zz', '5a2204z', 'b211', '0vtc0zz', '0s9f', '0yqa', '0vtb0zz', '0wjg0zz', '0tf4xzz', '0tf3xzz', '0tqb', '0wuf', '0t9b70z', '0vt00zz', '0dbn', 'bw20zzz', '0213', '0t9b30z', 'br3c', '3e1m39z', '0vts', 'cp1yyzz', 'b410', '0dbl', '0fbg', '0410', 'b246zzz', 'bw41zzz', '0ft4', 'b420', '0w9c', '5a1221z', '0210', '0b9m', '0bh18ez', '5a19', '0bh1', 'bp2w', '0bbm', '5a1d00z', 'b2111zz', '0270', '02vw3dz', 'b340zzz', '0bj08zz', 'b246zz4', '5a1955z', '3e0f7gc', '8e0zxy6', '4a00x4z', '0gbr', 'h47.10', '4a07x0z', '009u3zx', '0sr9', '0hbmxzx', 'b020', '5a1d60z', 'bw201zz', '0fb0', '0dtj', '0wqf', '0dbe8zx', '0db68zx', '0b11', '3e0g76z', '3e03gc', '0318', 'bt31', 'bt32', 'cg11', '0gth', '6a550z3', '02rf', 'b236', '4a0fx3z', '3e0436z', 'bq08', 'bq07', 'bq30', '0dta', '0dtb', '0dtf', '0dba', '0d1a', '0dtc', '0dth', '4a10x4z', '0dbb', '0w9g', 'bb4bzzz', '0w99', '0dqb', '0d1b', '0db8', '0d19', '0dj08zz', 'b424', '0db9', '0dc60zz', '3e1h78z', 'gzhzzzz', '0dh63uz', '03bs', '0qb3', '0nb0', 'bh02zzz', 'br39', '0bbk', '0bbn4zx', '0wbc3zx', '0w993zz', '0d15', '0dt6', 'bb24', '0fb03zx', '0fb4', '0w9d', 'b040zzz', '3e1g', 'bh32', '0fbg0zx', 'bq0lzzz', 'bp0nzzz', 'bq0mzzz', 'bp0pzzz', '0c99', '0cb9', '0cb4', '0cb1', '0cb6', '0HB0XZX', '0HB8XZX', '08j0xzz', '08rj', 'b825', '08btxzx', '3e0cx29', '08bsxzz', '0f14', 'b847zzz', 'bn23', '0bh17ez', 'bw28', '08j1xzz', 'b030yzz', '0890', '0891', '0212', '08bn', 'bn00zzz', 'b902zzz', '0016', '08q7xzz', 'bf45zzz', '0wjc4zz', '3e023gc', '4a07xbz', '3e013gc', 'b846zzz', 'b826', 'b845zzz', '3e0233z', '0d9w', 'b827', '3e0c3gc', '0hbv3zz', '0hbv0zz', '0HTV0ZZ', '0HRV076', '0hbkxzx', '0kxh', '0kxj', 'b936', 'b926', 'bq0g', '0ybm', 'br09zzz', 'bd14', 'br07zzz', '0hrnx74', '0y6t', '0y6x', 'bn26', '0nbv', '0nbt', 'bl31', '01nf', '0hb0xzz', 'br2c', 'db02', '00b20zz', '00u10jz', '0hhv', '079f', 'l90.5', '0y9d', '0hrlx74', '0ub0', '0FB03ZX', '07td', '0gt2', 'bf27', '0wbc4zx', '0d7a', '4a00', '009u', 'bh49zzz', 'bh02', 'd69.6', '0db4', '0f9g', 'b428', '0dj0', '0414', '0dte', '3e0g36z', 'c71y', '0fb24zz', '3e01', '0f99', '0b9f', '0bbf8zx', 'b53t', '0f504zz', '4a0f', 'b415', 'b414', '3e05305', '04l33dz', '0fbg3zx', '0f94', '0f7d', '0f79', '0ft9', '0dtg', '0d75', 'bu4c', '0dbh', '0dbqxzx', '0d7q', 'br37', 'BW20', 'br27', '0dbf', '06183dy', '3E0T3CZ', '09jkxzz', 'cg121zz', '0c97', 'bg34', '0cb7', '0ccx', 'bn0jzzz', 'cp1z1zz', '07b2', 'bn06zzz', '0gbn', 'bg43zzz', '0gtr', '07tm', 'bw4fzzz', '0nst', '0cq7', '0cq4', '0b91', 'bn25', '0cjs8zz', 'bn09', 'bn0hzzz', '0cb5', '07b1', 'bw3f', '0cq2', '0c00', '0c01', '0cq3', '0ntv', '0ct9', '0ct8', '00BM3ZX', '00bm', '0ct90zz', '0ct80zz', '00b0', '0w95', '0r9d3zx', 'bn29', 'bn39', 'bg23', '0cbh3zx', '07t2', '0pb3', '0gbc', 'b837', '00b1', '00c0', '0rs604z', 'b932', '09bt3zx', 'b318', 'b31c', '0090', '0D5A', '02rg', '3e0f7sf', '5a15223', '6a650zz', '0s9c', '0s9d', '0HB1XZX', '3e0r3cz', '0w8nxzz', '3e00xnz', '0y6h0z', '00pv', '3e013nz', '0t2dx0z', '0vb03zz', '00hv', '00hu', '0yq6', '0rg1', '5a09', '0vt08zz', 'BQ49ZZZ', '5a02', '07bm', '0ubg', '3e0337z', 'bn30', 'bw33', '01bg', 'b040', '0ut9', '0ub98zx', '0ut2', '0ut7', '0bjk8zz', '0gt24zz', '0cdxxz0', '0db5', 'bq42zzz', '0s9b', '0ttb8zz', '0gtk', 'bg44zzz', '0hbu', 'bh31', 'bh41zzz', '0htu0zz', '0x95', '02rg0jz', '0w993zx', '06hm33z', 'bw0czzz', '08br', 'BQ47ZZZ', 'bp0l', 'f13z', 'bn06', '0cb2', 'bn07', '0CB83ZX', '4a1zxqz', '07t1', '0wb5', 'bd13', 'b52k', '0cb93zx', '0cb83zx', 'BT41ZZZ', '0tt64zz', '0hb1xzx', '0h91', '0dh6', 'br0bzzz', 'cg12', '09jh8zz', '10d07z3', 'BP0BZZZ', '0psg', '0psl', '0psj', 'bq00', '0sj94zz', 'bq31', 'bq01', 'CP19', '0pbj', 'BH48ZZZ', 'bq3m', 'BQ0MZZZ', 'bq3l', 'BQ0LZZZ', 'br00zzz', 'a550z3', '06hn', '0dtp']\n","WARNING:tensorflow:From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DFm7TYGvPCBt","colab_type":"code","outputId":"9fca620d-ca04-4047-cade-23c4fcafe9ba","executionInfo":{"status":"ok","timestamp":1588871184684,"user_tz":-120,"elapsed":1043,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(labels_map)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["546"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"FI8igyRQHxqe","colab_type":"code","outputId":"842c8f49-db27-4493-bec0-8602fd600991","executionInfo":{"status":"ok","timestamp":1588772774663,"user_tz":-120,"elapsed":4217,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["!pip install joblib\n","import joblib\n","\n","labels_map = joblib.load('/content/drive/My Drive/codiesp/labels_map_bert_only_01.joblib')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.14.1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['/content/drive/My Drive/codiesp/labels_map_bert_only_01.joblib']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"pMLsCyxc_0UO","colab_type":"code","outputId":"5bcda349-ae1a-464a-df94-583c0ff78acc","executionInfo":{"status":"ok","timestamp":1588925459496,"user_tz":-120,"elapsed":70283,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["bert = load_trained_model_from_checkpoint(\n","    config_file=config_path,\n","    checkpoint_file=checkpoint_path,\n","    training=True,\n","    trainable=True,\n","    seq_len=128\n",")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L_S12pUXuj1j","colab_type":"code","colab":{}},"source":["# @title Build Custom Model\n","\n","inputs = bert.inputs[:2]\n","dense = bert.get_layer('NSP-Dense').output\n","dense1 = keras.layers.Dense(units=1000, activation='tanh') (dense)\n","outputs = keras.layers.Dense(units=len(labels_map), activation='softmax')(dense1)\n","\n","modelk = keras.models.Model(inputs, outputs)\n","modelk.compile(\n","    RAdam(lr=LR),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy'],\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gep9SctVvQ96","colab_type":"code","outputId":"22ab62bc-2d84-4254-91eb-68b176a134a8","executionInfo":{"status":"ok","timestamp":1588925460961,"user_tz":-120,"elapsed":71726,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["# @title Initialize Variables\n","sess = K.get_session()\n","uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n","init_op = tf.variables_initializer(\n","    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",")\n","sess.run(init_op)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yGYsRQRJvVsL","colab_type":"code","outputId":"24fbc8a7-7778-409d-b0a1-0cd245f390c7","colab":{"base_uri":"https://localhost:8080/","height":955}},"source":["# @title Fit\n","\n","filepath=\"/content/drive/My Drive/codiesp/task2_bert_with_empty.{epoch:05d}-{val_loss:.5f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_sparse_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","callbacks_list = [\n","    checkpoint\n","]\n","\n","modelk.fit(\n","    indices_train,\n","    train_labes_indexes,\n","    epochs=20,\n","    batch_size=32,\n","    validation_split = 0.10,\n","    callbacks=callbacks_list\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 5544 samples, validate on 616 samples\n","Epoch 1/20\n","5544/5544 [==============================] - 725s 131ms/step - loss: 4.4012 - sparse_categorical_accuracy: 0.4363 - val_loss: 2.8934 - val_sparse_categorical_accuracy: 0.6380\n","\n","Epoch 00001: val_sparse_categorical_accuracy improved from -inf to 0.63799, saving model to /content/drive/My Drive/codiesp/task2_bert_with_empty.00001-2.89337.hdf5\n","Epoch 2/20\n","5544/5544 [==============================] - 709s 128ms/step - loss: 3.1583 - sparse_categorical_accuracy: 0.5738 - val_loss: 2.7203 - val_sparse_categorical_accuracy: 0.6380\n","\n","Epoch 00002: val_sparse_categorical_accuracy did not improve from 0.63799\n","Epoch 3/20\n","5544/5544 [==============================] - 715s 129ms/step - loss: 2.9348 - sparse_categorical_accuracy: 0.5738 - val_loss: 2.6881 - val_sparse_categorical_accuracy: 0.6396\n","\n","Epoch 00003: val_sparse_categorical_accuracy improved from 0.63799 to 0.63961, saving model to /content/drive/My Drive/codiesp/task2_bert_with_empty.00003-2.68807.hdf5\n","Epoch 4/20\n","5544/5544 [==============================] - 714s 129ms/step - loss: 2.7905 - sparse_categorical_accuracy: 0.5758 - val_loss: 2.6532 - val_sparse_categorical_accuracy: 0.6494\n","\n","Epoch 00004: val_sparse_categorical_accuracy improved from 0.63961 to 0.64935, saving model to /content/drive/My Drive/codiesp/task2_bert_with_empty.00004-2.65322.hdf5\n","Epoch 5/20\n","5544/5544 [==============================] - 708s 128ms/step - loss: 2.6681 - sparse_categorical_accuracy: 0.5826 - val_loss: 2.6702 - val_sparse_categorical_accuracy: 0.6461\n","\n","Epoch 00005: val_sparse_categorical_accuracy did not improve from 0.64935\n","Epoch 6/20\n","5544/5544 [==============================] - 705s 127ms/step - loss: 2.5675 - sparse_categorical_accuracy: 0.5891 - val_loss: 2.6843 - val_sparse_categorical_accuracy: 0.6575\n","\n","Epoch 00006: val_sparse_categorical_accuracy improved from 0.64935 to 0.65747, saving model to /content/drive/My Drive/codiesp/task2_bert_with_empty.00006-2.68432.hdf5\n","Epoch 7/20\n","5544/5544 [==============================] - 706s 127ms/step - loss: 2.4284 - sparse_categorical_accuracy: 0.5990 - val_loss: 2.6958 - val_sparse_categorical_accuracy: 0.6591\n","\n","Epoch 00007: val_sparse_categorical_accuracy improved from 0.65747 to 0.65909, saving model to /content/drive/My Drive/codiesp/task2_bert_with_empty.00007-2.69579.hdf5\n","Epoch 8/20\n","5544/5544 [==============================] - 710s 128ms/step - loss: 2.2811 - sparse_categorical_accuracy: 0.6172 - val_loss: 2.7104 - val_sparse_categorical_accuracy: 0.6575\n","\n","Epoch 00008: val_sparse_categorical_accuracy did not improve from 0.65909\n","Epoch 9/20\n","5544/5544 [==============================] - 707s 128ms/step - loss: 2.1184 - sparse_categorical_accuracy: 0.6392 - val_loss: 2.6998 - val_sparse_categorical_accuracy: 0.6607\n","\n","Epoch 00009: val_sparse_categorical_accuracy improved from 0.65909 to 0.66071, saving model to /content/drive/My Drive/codiesp/task2_bert_with_empty.00009-2.69984.hdf5\n","Epoch 10/20\n","5544/5544 [==============================] - 763s 138ms/step - loss: 1.9858 - sparse_categorical_accuracy: 0.6571 - val_loss: 2.6249 - val_sparse_categorical_accuracy: 0.6688\n","\n","Epoch 00010: val_sparse_categorical_accuracy improved from 0.66071 to 0.66883, saving model to /content/drive/My Drive/codiesp/task2_bert_with_empty.00010-2.62491.hdf5\n","Epoch 11/20\n","5544/5544 [==============================] - 735s 133ms/step - loss: 1.8551 - sparse_categorical_accuracy: 0.6726 - val_loss: 2.7216 - val_sparse_categorical_accuracy: 0.6688\n","\n","Epoch 00011: val_sparse_categorical_accuracy did not improve from 0.66883\n","Epoch 12/20\n","5544/5544 [==============================] - 760s 137ms/step - loss: 1.7204 - sparse_categorical_accuracy: 0.6952 - val_loss: 2.6893 - val_sparse_categorical_accuracy: 0.6494\n","\n","Epoch 00012: val_sparse_categorical_accuracy did not improve from 0.66883\n","Epoch 13/20\n","5536/5544 [============================>.] - ETA: 1s - loss: 1.6182 - sparse_categorical_accuracy: 0.7054"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I_2g0uSEOu54","colab_type":"code","colab":{}},"source":["#modelk.save('/content/drive/My Drive/codiesp/final_model_only_01.h5')\n","modelk.load_weights('/content/drive/My Drive/codiesp/task2_bert_with_empty.00010-2.62491.hdf5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jzw09XfMlPY","colab_type":"code","outputId":"940e5baa-1785-483b-ec04-986ee70d3c24","executionInfo":{"status":"error","timestamp":1588926522673,"user_tz":-120,"elapsed":1133425,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["# @title Predict\n","predicts = modelk.predict(indices_test, verbose=True)"],"execution_count":11,"outputs":[{"output_type":"stream","text":[" 2176/53220 [>.............................] - ETA: 6:43:05"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-7dcdbea13df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"NzXHB5TAIRo_","colab_type":"code","colab":{}},"source":["res_encoded = []\n","for a in predicts:\n","    val = a.argmax()\n","    res_encoded.append(labels_map[val])\n","\n","for i in range(0,len(res_encoded)):\n","  label = res_encoded[i]\n","  if label != \n","\n","#print(res_encoded)\n","#res_labels = le.inverse_transform(DataFrame.res_encoded)\n","\n","#print('Testing accuracy %s' % accuracy_score(test_labels, res_encoded))\n","#print('Testing F1 score: {}'.format(f1_score(test_labels, res_encoded, average='weighted')))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f92gI4N9LRdj","colab_type":"code","colab":{}},"source":["extracted_res = []\n","extractede_ids =[]\n","j =0\n","previous_id = test_ids[0]\n","\n","for result in predicts:\n","  id = test_ids[j]\n","\n","  if id != previous_id:\n","    od = OrderedDict(max_vals) \n","    #print(str(id)+' '+str(od))\n","\n","    for key, value in od.items():\n","      extracted_res.append(value.lower())\n","      extractede_ids.append(previous_id)\n","    max_vals = {}\n","    previous_id = id\n","\n","  i = 0\n","  for a in result:\n","    if a > 0.10:\n","      if labels_map[i] != 'emp':\n","        max_vals[str(a)] = labels_map[i]\n","    i = i+1\n","  if len(max_vals) == 0:\n","    v = result.max()\n","    index = result.argmax()\n","    max_vals[str(v)] = labels_map[index]\n","\n","  j = j+1\n","\n","#Last item\n","od = OrderedDict(max_vals) \n","\n","for key, value in od.items():\n","    extracted_res.append(value.lower())\n","    extractede_ids.append(previous_id)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCil8t_RLstY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":244},"outputId":"58eaa0ce-6dfb-4e4f-9924-4b0262cb04ad","executionInfo":{"status":"error","timestamp":1588926523396,"user_tz":-120,"elapsed":685,"user":{"displayName":"MARCO POLIGNANO","photoUrl":"","userId":"14417778915350348725"}}},"source":["file = open('task2_run3_bert_multiclass.tsv','w+')\n","\n","for i in range(0, len(extracted_res)):\n","  file.write(str(extractede_ids[i])+'\\t'+str(extracted_res[i])+'\\n')\n","  file.flush()\n","\n","file.close()"],"execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-3e11fd74b5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'task2_run3_bert_multiclass.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextractede_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'extracted_res' is not defined"]}]},{"cell_type":"code","metadata":{"id":"muXNFXxxvDI6","colab_type":"code","colab":{}},"source":["!pip install scikit-learn\n","from sklearn.metrics import classification_report\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wce_P7vsvw6V","colab_type":"code","colab":{}},"source":["print(classification_report(test_labels, res_encoded,digits=5))"],"execution_count":0,"outputs":[]}]}